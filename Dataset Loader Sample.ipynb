{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# from torchtext.data import Dataset, BucketIterator\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modified from https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/Pytorch/more_advanced/image_captioning/get_loader.py\n",
    "class Vocabulary:\n",
    "    def __init__(self, freq_thres=1):\n",
    "        self.itos = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "        self.stoi = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
    "        self.freq_threshold = freq_thres\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenizer_seq(fasta_seq):\n",
    "#         print(fasta_seq)\n",
    "        return [str(x) for x in list(fasta_seq)]\n",
    "\n",
    "    def build_vocabulary(self, seq_list):\n",
    "        frequencies = {}\n",
    "        idx = 4\n",
    "        for idx1, base in enumerate(list('acgut')):\n",
    "            self.stoi[base] = idx+idx1\n",
    "            self.itos[idx+idx1] = base\n",
    "\n",
    "#         for each_seq in seq_list:\n",
    "#             for base in self.tokenizer_seq(each_seq):\n",
    "#                 base = base.lower()\n",
    "#                 if base in self.stoi:\n",
    "#                     continue\n",
    "#                 if base not in frequencies:\n",
    "#                     frequencies[base] = 1\n",
    "\n",
    "#                 else:\n",
    "#                     frequencies[base] += 1\n",
    "\n",
    "#                 if frequencies[base] == self.freq_threshold:\n",
    "#                     self.stoi[base] = idx\n",
    "#                     self.itos[idx] = base\n",
    "#                     idx += 1\n",
    "\n",
    "    def numericalize(self, fasta_seq):\n",
    "        tokenized_seq = self.tokenizer_seq(fasta_seq.lower())\n",
    "\n",
    "        return [\n",
    "            self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"]\n",
    "            for token in tokenized_seq\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, filename, freq_threshold=5):\n",
    "        self.df = pd.read_csv(filename, header=None)\n",
    "\n",
    "        # Get Sequences (miRNA and Target mRNA)\n",
    "        # Dataset Column Positions - miRNA, mRNA, miRNA_Seq, mRNA_Seq, Relative_score\n",
    "        self.mirna = self.df.iloc[:, 2]\n",
    "        self.mrna = self.df.iloc[:, 3]\n",
    "        self.rel_score = self.df.iloc[:, -1]\n",
    "        \n",
    "        #concatenating row-wise to create a combined vocabulary\n",
    "        all_seq = self.mirna[:] + self.mrna\n",
    "        \n",
    "        # Initialize vocabulary and build vocab\n",
    "        self.vocab = Vocabulary(freq_threshold)\n",
    "        self.vocab.build_vocabulary(all_seq.tolist())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def numericalize_seq(self,seq):\n",
    "        numericalized_seq = [self.vocab.stoi[\"<SOS>\"]]\n",
    "        numericalized_seq += self.vocab.numericalize(seq)\n",
    "        numericalized_seq.append(self.vocab.stoi[\"<EOS>\"])\n",
    "        return numericalized_seq\n",
    "    def get_vocabulary(self):\n",
    "        return self.vocab.stoi\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        mirna, mrna, score = torch.tensor(self.numericalize_seq(self.mirna[index])), torch.tensor(self.numericalize_seq(self.mrna[index])),torch.tensor(self.rel_score[index])\n",
    "#         mirna, mrna, score = mirna.unsqueeze(0), mrna.unsqueeze(0), score.unsqueeze(0)\n",
    "#         print(mirna.size(), mrna.size())\n",
    "        return mirna, mrna, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCollate:\n",
    "    def __init__(self, pad_idx):\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "    def __call__(self, batch):\n",
    "#         imgs = [item[0].unsqueeze(0) for item in batch]\n",
    "#         imgs = torch.cat(imgs, dim=0)\n",
    "#         targets = [item[1] for item in batch]\n",
    "#         targets = pad_sequence(targets, batch_first=False, padding_value=self.pad_idx)\n",
    "        \n",
    "        mirna = [item[0] for item in batch]\n",
    "        mrna = [item[1] for item in batch]\n",
    "        \n",
    "        mirna = pad_sequence(mirna, batch_first=True, padding_value=self.pad_idx)\n",
    "        mrna = pad_sequence(mrna, batch_first=True, padding_value=self.pad_idx)\n",
    "\n",
    "        return mirna, mrna, [item[2] for item in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a ready Loader and the Dataset Class for the Sequence\n",
    "def get_loader(\n",
    "    seq_csv,\n",
    "    batch_size=5,\n",
    "    num_workers=8,\n",
    "    shuffle=True,\n",
    "    pin_memory=True\n",
    "):\n",
    "    dataset = SequenceDataset(filename=seq_csv)\n",
    "\n",
    "    pad_idx = dataset.vocab.stoi[\"<PAD>\"]\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=shuffle,\n",
    "        pin_memory=pin_memory,\n",
    "        collate_fn=MyCollate(pad_idx=pad_idx)\n",
    "    )\n",
    "\n",
    "    return loader, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader, dataset = get_loader(\"dogtest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([1, 4, 7, 4, 7, 4, 5, 4, 6, 6, 6, 6, 6, 4, 6, 4, 5, 7, 5, 7, 7, 4, 7, 2]) targets tensor([1, 8, 6,  ..., 0, 0, 0])\n",
      "1 tensor([1, 4, 7, 4, 7, 4, 5, 4, 6, 6, 6, 6, 6, 4, 6, 4, 5, 7, 5, 7, 7, 4, 7, 2]) targets tensor([1, 6, 6,  ..., 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for idx, (mirna, mrna, score) in enumerate(loader):\n",
    "    if idx == 2:\n",
    "        break\n",
    "    print(idx, mirna[0], \"targets\", mrna[0])\n",
    "# data = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
